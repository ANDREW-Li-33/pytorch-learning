{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **torch.autograd**\n",
        "<hr>\n",
        "automatic differentiation: method that computes derivatives by applying the chain rule.\n",
        "<hr>\n",
        "An automatic differentiation engine calculates derivatives for you in this way, which makes it much easier to compute gradients\n",
        "<hr>\n",
        "torch.autograd is PyTorch's automatic differentiation engine"
      ],
      "metadata": {
        "id": "wdNUk1B2b_uz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training a Neural Network occurs in two steps:\n",
        "1. Forward Propagation: NN makes its best guess about the correct output given an input\n",
        "2. Backward Propagation: NN computes gradients by propagating errors backwards through the network and using the chain rule"
      ],
      "metadata": {
        "id": "WFdHrbcRdgpP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-ODOLSLbb7fW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision.models import resnet18, ResNet18_Weights"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "data = torch.rand(1, 3, 64, 64)\n",
        "labels = torch.rand(1, 1000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_090f6yhJk5",
        "outputId": "9a9ab717-b1ef-4386-9e81-2ba088f2677b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 134MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model(data)\n",
        "loss = (prediction - labels).sum\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "1vqyzkEch-pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**optimizer**: a method to update the model parameters to minimize loss \\\\\n",
        "\n",
        "**SGD** (stochastic gradient descent): a simple optimizer that updates parameters based on the gradient of the loss \\\\\n",
        "\n",
        "**learning rate**: determines how big of a step we take in the direction of the gradient \\\\\n",
        "\n",
        "**momentum**: helps accelerate updates by incorporating a fraction of the previous update, which smooths the descent process\n"
      ],
      "metadata": {
        "id": "MfKDJHSajl3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
      ],
      "metadata": {
        "id": "uVdBUL43lKRj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ".step() initiates gradient descent"
      ],
      "metadata": {
        "id": "6dr0KbbJlVRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer.step()"
      ],
      "metadata": {
        "id": "tGE4VLW3lTJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "requires_grad for a tensor is False by default. If we want PyTorch to track operations on a tensor, we need to set requires_grad = True"
      ],
      "metadata": {
        "id": "AyaCMVp2niQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor((2., 3.), requires_grad=True)\n",
        "b = torch.tensor((6., 4.), requires_grad = True)\n",
        "\n",
        "Q = 3*a**3 - b**2    # our error / loss, we want to know how changes in a and b affect Q\n",
        "\n",
        "external_grad = torch.tensor([1., 1.])\n",
        "Q.backward(gradient=external_grad)         # automatically computes partial derivatives for gradients"
      ],
      "metadata": {
        "id": "wKJcZr08m4fA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "check if collected gradients are correct"
      ],
      "metadata": {
        "id": "w5Ml4_FnpOKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(9*a**2 == a.grad)\n",
        "print(-2*b == b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJvZfq8no0n2",
        "outputId": "66438a7b-8cd6-4dc6-8654-9a88da8e5274"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([True, True])\n",
            "tensor([True, True])\n"
          ]
        }
      ]
    }
  ]
}